# TASK-0001.4.4.3: Implement Compression in set() and Decompression in get()

**Parent Story**: [STORY-0001.4.4](README.md)
**Status**: ✅ Complete
**Estimated Hours**: 3
**Actual Hours**: 3

## Objective

Implement transparent compression in EmbeddingCache.set() and decompression in EmbeddingCache.get(), update file extension to .safetensors.zst, and implement all BDD step definitions. This is the core implementation task.

## BDD Progress

**Before this task**: 0/2 scenarios passing
**After this task**: 2/2 scenarios passing ✅

**Scenarios for this task:**
- Scenario 1: Embedding cache compressed on disk (full implementation)
- Scenario 2: Decompression transparent to search (full implementation)

## Implementation Checklist

### Unit Tests First (TDD - RED)
- [ ] Create `tests/unit/storage/test_embedding_cache_compression.py`
- [ ] Write 8+ tests for EmbeddingCache.set() with compression:
  - [ ] Test: set() writes .safetensors.zst file (not .safetensors)
  - [ ] Test: set() compresses safetensors bytes before writing
  - [ ] Test: set() preserves all embedding metadata
  - [ ] Test: set() handles multiple embeddings correctly
  - [ ] Test: set() handles empty embedding list
  - [ ] Test: set() creates cache directory if missing
  - [ ] Test: set() overwrites existing cache file
  - [ ] Test: set() file is smaller than uncompressed safetensors
- [ ] Write 11+ tests for EmbeddingCache.get() with decompression:
  - [ ] Test: get() reads .safetensors.zst file correctly
  - [ ] Test: get() decompresses bytes before loading safetensors
  - [ ] Test: get() reconstructs embeddings identically
  - [ ] Test: get() preserves vector values (no precision loss)
  - [ ] Test: get() preserves token_count metadata
  - [ ] Test: get() preserves cost_usd metadata
  - [ ] Test: get() returns None for missing file
  - [ ] Test: get() returns None for corrupted compressed data
  - [ ] Test: get() logs warning on decompression failure
  - [ ] Test: get() returns None for old .safetensors files (backward compat)
    - Assertion: `assert cache.get("old_blob_sha") is None` (no migration support)
  - [ ] Test: Compressed file starts with zstd magic bytes (0x28B52FFD)
    - Assertion: `assert path.read_bytes()[:4] == b'\x28\xB5\x2F\xFD'`
- [ ] Run tests - all fail ✓

### Implementation (GREEN)
- [ ] Update EmbeddingCache.set() per story lines 109-133:
  - [ ] Change file path to use `.safetensors.zst` extension
  - [ ] Serialize tensors using save() (returns bytes, not save_file())
  - [ ] Compress with zstd (level 3)
  - [ ] Write compressed bytes with path.write_bytes()
- [ ] Update EmbeddingCache.get() per story lines 65-107:
  - [ ] Change file path to use `.safetensors.zst` extension
  - [ ] Read and decompress file with zstd
  - [ ] Parse safetensors header for metadata (struct + json pattern)
  - [ ] Load tensors using load() (accepts bytes, not load_file())
  - [ ] Reconstruct Embedding objects from tensors + metadata
  - [ ] Handle decompression errors gracefully (log warning, return None)
- [ ] Run tests - all pass ✓

### Refactor (if needed)
- [ ] Clean up any duplicated code
- [ ] Ensure error handling is consistent
- [ ] Verify docstrings are accurate

### BDD Implementation
- [ ] Implement step in `tests/e2e/steps/test_embedding.py`: "Given I have a test repository with 10 Python files"
- [ ] Implement step: "When I index the repository"
- [ ] Implement step: "When I check the .gitctx/embeddings/ directory"
- [ ] Implement step: "Then cache files should have .safetensors.zst extension"
- [ ] Implement step: "And cache size should be approximately 8% smaller than uncompressed"
  - Assertion: `assert 10.5 <= cache_size_mb <= 11.5` (11MB target ±5% tolerance)
- [ ] Implement step: "Given I have indexed a repository with compressed cache"
- [ ] Implement step: "When I search for authentication"
- [ ] Implement step: "Then search results should be returned correctly"
- [ ] Implement step: "And decompression overhead should be minimal"
  - Assertion: `assert search_time_ms < 100` (decompression adds <100ms)
- [ ] Run BDD tests - 2/2 scenarios passing ✓

### Verification
- [ ] All unit tests pass (19+ tests: 8 for set(), 11 for get())
- [ ] All BDD scenarios pass (2/2 ✅)
- [ ] Code coverage >90%
- [ ] mypy passes (no type errors)
- [ ] ruff check and format pass

## Files to Create/Modify

- CREATE: `tests/unit/storage/test_embedding_cache_compression.py` (~220 lines, 19+ tests)
- MODIFY: `src/gitctx/storage/embedding_cache.py` (update set() and get() methods)
- MODIFY: `tests/e2e/steps/test_embedding.py` (implement 9 step definitions for compression scenarios)

## Pattern Reuse

- **Error handling**: Log warnings on cache failures, return None (existing pattern in EmbeddingCache)
- **Safetensors API**: save_file() and load_file() with bytes (existing pattern)
- **BDD step implementation**: Follow existing step definition patterns from other features

## Performance Targets

- Compression: <10ms overhead per file
- Decompression: <5ms overhead per file
- File size: 90-92% of uncompressed safetensors (8-10% reduction)
- API transparency: No changes required to callers

## Notes

- Use try/except around decompression to handle corrupted cache gracefully
- **Metadata parsing pattern**: Safetensors stores metadata in JSON header
  - First 8 bytes: header size (little-endian uint64)
  - Next N bytes: JSON header with `__metadata__` field
  - This is the official pattern for extracting metadata from bytes
- Verify compression doesn't break existing embedding reconstruction logic
- All BDD scenarios should pass after this task (story is feature-complete)
