# TASK-0001.2.3.4: Configuration integration, cost tracking, and final BDD scenarios

**Parent**: [STORY-0001.2.3](README.md)
**Status**: ✅ Complete
**Estimated Hours**: 4
**Actual Hours**: 4

## Objective

Integrate OpenAIEmbedder with GitCtxSettings configuration, implement cost tracking and progress logging, implement final BDD scenarios, and complete the story with all 10/10 scenarios passing.

## Implementation Checklist

### Configuration Integration
- [ ] Verify GitCtxSettings API key handling:
  - [ ] Check `src/gitctx/core/config.py` - routes `api_keys.openai` to UserConfig ✅
  - [ ] Check `src/gitctx/core/user_config.py` - has `ApiKeys.openai` field ✅
  - [ ] Test loading: `settings = GitCtxSettings(); key = settings.get("api_keys.openai")`
- [ ] Update OpenAIEmbedder to use GitCtxSettings:
  ```python
  class OpenAIEmbedder:
      def __init__(self, settings: GitCtxSettings, cache: EmbeddingCache):
          # Get API key from settings (checks OPENAI_API_KEY env var first)
          api_key = settings.get("api_keys.openai")
          if not api_key:
              raise ConfigurationError(
                  "OpenAI API key not configured. Set via:\n"
                  "  gitctx config set api_keys.openai sk-...\n"
                  "Or set OPENAI_API_KEY environment variable"
              )

          self.cache = cache
          self._embeddings = OpenAIEmbeddings(
              openai_api_key=api_key,
              model="text-embedding-3-large"
          )
  ```
- [ ] Write integration tests:
  - [ ] `test_embedder_uses_api_key_from_settings()` - Reads from GitCtxSettings
  - [ ] `test_embedder_raises_if_no_api_key()` - ConfigurationError when key missing
  - [ ] `test_embedder_respects_env_var()` - OPENAI_API_KEY takes precedence
- [ ] Run integration tests: `uv run pytest tests/unit/embeddings/test_integration.py -v`

### Cost Tracking and Progress Logging
- [ ] Implement aggregate cost tracking in OpenAIEmbedder:
  ```python
  async def embed_with_cache(
      chunker: ChunkerProtocol,
      embedder: EmbedderProtocol,
      cache: EmbeddingCache,
      blob_record: BlobRecord
  ) -> list[Embedding]:
      """Generate embeddings with caching.

      Args:
          chunker: Code chunker
          embedder: Embedding generator
          cache: Embedding cache
          blob_record: Git blob to process

      Returns:
          List of embeddings (from cache or newly generated)
      """
      # Check cache by blob SHA
      cached = cache.get(blob_record.sha)
      if cached:
          return cached

      # Chunk the blob
      chunks = chunker.chunk(blob_record.content, blob_record.path)

      # Generate embeddings
      embeddings = await embedder.embed_chunks(chunks, blob_record.sha)

      # Store in cache
      cache.put(blob_record.sha, embeddings)

      return embeddings
  ```
- [ ] Create `src/gitctx/core/embedding.py` (new file) for `embed_with_cache()` helper
- [ ] Write integration tests:
  - [ ] `test_embed_with_cache_hit()` - Blob in cache → return cached
  - [ ] `test_embed_with_cache_miss()` - Blob not in cache → generate
  - [ ] `test_embed_with_cache_stores_result()` - Result stored after generation
  - [ ] `test_embed_with_cache_updates_on_change()` - New SHA → new embeddings
- [ ] Run integration tests: `uv run pytest tests/unit/embeddings/test_embedding_integration.py -v`

### Pipeline Integration Test
- [ ] Create full end-to-end pipeline test:
  - [ ] Use `git_repo_factory` to create test repo with Python files
  - [ ] Walk repository blobs (use CommitWalker)
  - [ ] Chunk each blob (use Chunker)
  - [ ] Generate embeddings (use OpenAIEmbedder)
  - [ ] Verify metadata (blob_sha, chunk_index) correct
  - [ ] Verify all embeddings have 3072 dimensions
  - [ ] Verify cost calculation accurate
- [ ] Test file: `tests/unit/embeddings/test_pipeline_integration.py`
- [ ] Run pipeline test: `uv run pytest tests/unit/embeddings/test_pipeline_integration.py -v`

### BDD Implementation (Final Scenarios)

**Scenario 5: Cache embeddings by blob SHA**
- [ ] Implement step: "Given a blob has been embedded previously"
  - [ ] Create blob, generate embeddings, store in cache
- [ ] Implement step: "When I request embeddings for the same blob SHA"
  - [ ] Call embed_with_cache with same blob_sha
- [ ] Implement step: "Then cached embeddings should be returned"
  - [ ] Assert embeddings match cached version
  - [ ] Assert no API call made (mock spy)

**Scenario 6: Generate new embeddings for uncached blobs**
- [ ] Implement step: "Given a new blob not in cache"
  - [ ] Create blob with new SHA
- [ ] Implement step: "When I request embeddings"
  - [ ] Call embed_with_cache
- [ ] Implement step: "Then new embeddings should be generated"
  - [ ] Assert API called (mock spy)
  - [ ] Assert embeddings stored in cache

**Scenario 7: Validate embedding dimensions**
- [ ] Implement step: "Given an embedding is generated from the API"
  - [ ] Generate embedding via OpenAIEmbedder
- [ ] Implement step: "When I validate the embedding"
  - [ ] Check len(embedding.vector)
- [ ] Implement step: "Then it should have exactly 3072 dimensions"
  - [ ] Assert len(embedding.vector) == 3072

**Scenario 10: Reject initialization without API key**
- [ ] Already stubbed in TASK-0001.2.3.2
- [ ] Implement step: "When I attempt to initialize the OpenAIEmbedder"
  - [ ] Try to create OpenAIEmbedder without API key
- [ ] Verify ConfigurationError raised

- [ ] Run all BDD tests: `uv run pytest tests/e2e/features/embedding.feature -v`
- [ ] Verify 10/10 scenarios passing ✅

### Final Verification
- [ ] Run ALL unit tests: `uv run pytest tests/unit/embeddings/ -v`
- [ ] Run ALL BDD scenarios: `uv run pytest tests/e2e/features/embedding.feature -v`
- [ ] Verify 10/10 BDD scenarios passing ✅
- [ ] Run full test suite: `uv run pytest -v`
- [ ] Quality gates: `uv run ruff check src tests && uv run ruff format src tests && uv run mypy src && uv run pytest`
- [ ] Coverage check: `uv run pytest --cov=src/gitctx --cov-report=term-missing`
- [ ] Update story README:
  - [ ] Progress: 100% (4/4 tasks complete)
  - [ ] BDD Progress: 10/10 scenarios passing ✅
  - [ ] All tasks marked ✅ Complete

## Pattern Reuse

**Existing Patterns to Follow:**
- Cache integration: EmbeddingCache implemented in TASK-2 (`src/gitctx/core/embedding_cache.py`)
- Config pattern: `src/gitctx/core/config.py` (GitCtxSettings)
- Factory pattern: `config_factory` (tests/unit/conftest.py:604)
- Integration tests: `tests/unit/core/test_chunker_integration.py`

**Fixtures Available:**
- `git_repo_factory` (tests/unit/conftest.py:309) - Custom test repos
- `config_factory` (tests/unit/conftest.py:604) - Generate test configs
- `code_blob_factory` (tests/unit/conftest.py:870) - Generate test blobs
- `e2e_git_repo_factory` (tests/e2e/conftest.py:254) - E2E repos

## Integration Architecture

```
┌─────────────────────────────────────────────────────────┐
│                    User / CLI                           │
└────────────────────┬────────────────────────────────────┘
                     │
                     ▼
           ┌─────────────────────┐
           │  embed_with_cache   │ ← Helper function
           └─────────┬───────────┘
                     │
         ┌───────────┼───────────┐
         │           │           │
         ▼           ▼           ▼
    ┌────────┐  ┌─────────┐  ┌──────┐
    │Chunker │  │Embedder │  │Cache │
    └────────┘  └─────────┘  └──────┘
         │           │           │
         │           ▼           │
         │    ┌──────────────┐  │
         │    │  LangChain   │  │
         │    │OpenAIEmbeds  │  │
         │    └──────────────┘  │
         │                      │
         └──────────┬───────────┘
                    │
                    ▼
            ┌───────────────┐
            │  Embeddings   │
            │  w/ Metadata  │
            └───────────────┘
```

## Dependencies

**Prerequisite Stories:**
- STORY-0001.1.2: Configuration (provides GitCtxSettings) ✅
- STORY-0001.2.2: Blob Chunking (provides CodeChunk input) ✅

**Internal Components (from TASK-2):**
- `EmbeddingCache` - Implemented in `src/gitctx/core/embedding_cache.py`
- `EmbedderProtocol` - Defined in `src/gitctx/core/protocols.py`
- `Embedding` dataclass - Defined in `src/gitctx/core/models.py`

**Check Dependencies:**
- [ ] Verify EmbeddingCache exists: `grep -r "class EmbeddingCache" src/`
- [ ] Verify GitCtxSettings exists: `grep -r "class GitCtxSettings" src/`
- [ ] Verify Chunker exists: `grep -r "class.*Chunker" src/`

## Notes

- EmbeddingCache: Implemented in TASK-2 (`src/gitctx/core/embedding_cache.py`)
- Cache integration: Already built into OpenAIEmbedder (TASK-3)
- Integration test uses real git repos via git_repo_factory
- Final verification critical: ALL 10 BDD scenarios must pass
- This task completes the story (100% done)

## Expected Outcome

**BDD Progress**: 10/10 scenarios passing ✅
**Story Status**: ✅ Complete (100%)
**Result**: Full embedding generation pipeline working with caching and configuration

**Deliverables:**
- ✅ OpenAIEmbedder wrapping LangChain
- ✅ embed_with_cache() helper function
- ✅ Full pipeline integration test
- ✅ All 10 BDD scenarios passing
- ✅ Story complete and ready for STORY-0001.2.4 (Vector Storage)

---

**Created**: 2025-10-07
**Last Updated**: 2025-10-07
