# TASK-0001.2.3.2: Define protocols, models, and EmbeddingCache + add dependencies

**Parent**: [STORY-0001.2.3](README.md)
**Status**: ðŸ”µ Not Started
**Estimated Hours**: 4
**Actual Hours**: -

## Objective

Define embedding protocol and data structures with unit tests, and add LangChain v1.0 alpha dependencies. This creates the foundation for provider-agnostic embedding generation (OpenAI, Anthropic, Cohere, etc.).

## Implementation Checklist

### Add Dependencies
- [ ] Add to `pyproject.toml` dependencies:
  ```toml
  "langchain-core>=1.0.0a0",      # Core abstractions
  "langchain-openai>=1.0.0a0",    # OpenAI embeddings provider
  "tiktoken>=0.5.0",              # Token counting (peer dependency)
  "safetensors>=0.4.0",           # Embedding cache storage
  ```
- [ ] Run `uv sync` to install new dependencies
- [ ] Verify imports work:
  - [ ] `uv run python -c "from langchain_openai import OpenAIEmbeddings"`
  - [ ] `uv run python -c "from safetensors.numpy import save_file, load_file"`

### Define Embedding Dataclass (TDD - Tests First)
- [ ] Create `tests/unit/embeddings/` directory
- [ ] Create `tests/unit/embeddings/__init__.py`
- [ ] Create `tests/unit/embeddings/test_embedding.py`
- [ ] Write unit tests BEFORE implementation:
  - [ ] `test_embedding_creation_with_all_fields()` - Valid embedding
  - [ ] `test_embedding_vector_dimensions()` - Exactly 3072 dimensions
  - [ ] `test_embedding_primitives_only()` - No numpy arrays (FFI compatible)
  - [ ] `test_embedding_serialization()` - asdict() works
  - [ ] `test_embedding_immutable()` - Frozen dataclass (optional)
- [ ] Run tests - all fail âœ“ (RED phase)
- [ ] Add `Embedding` dataclass to `src/gitctx/core/protocols.py`:
  ```python
  @dataclass(frozen=True)
  class Embedding:
      """Embedding vector with metadata (FFI-compatible, primitives only)."""
      vector: list[float]      # 3072 dimensions for text-embedding-3-large
      token_count: int         # Tokens in source chunk
      model: str               # e.g., "text-embedding-3-large"
      cost_usd: float          # API cost for this embedding
      blob_sha: str            # Git blob SHA
      chunk_index: int         # Index within blob's chunks
  ```
- [ ] Add docstring with FFI compatibility note (no numpy, no Path objects)
- [ ] Run tests - all pass âœ“ (GREEN phase)

### Define EmbedderProtocol
- [ ] Add `EmbedderProtocol` to `src/gitctx/core/protocols.py`:
  ```python
  class EmbedderProtocol(Protocol):
      """Abstract interface for embedding providers (OpenAI, Anthropic, etc.)."""

      async def embed_chunks(
          self,
          chunks: list[CodeChunk],
          blob_sha: str
      ) -> list[Embedding]:
          """Generate embeddings for code chunks.

          Args:
              chunks: Code chunks to embed
              blob_sha: Git blob SHA for metadata

          Returns:
              List of embeddings with metadata
          """
          ...

      def estimate_cost(self, token_count: int) -> float:
          """Estimate API cost for given token count.

          Args:
              token_count: Number of tokens

          Returns:
              Estimated cost in USD
          """
          ...
  ```
- [ ] Add comprehensive docstrings with examples
- [ ] Type check: `uv run mypy src/gitctx/core/protocols.py`

### Unit Tests for Protocol Compliance
- [ ] Create `tests/unit/embeddings/test_protocol.py`
- [ ] Write test for protocol compliance:
  ```python
  def test_embedder_protocol_compliance():
      """Verify OpenAIEmbedder implements EmbedderProtocol."""
      # Will be implemented in TASK-0001.2.3.3
      # This test defines the contract
      pass
  ```
- [ ] Add parametrized test for dimension validation
- [ ] Add test for cost calculation formula

### EmbeddingCache Implementation (TDD - Tests First)
- [ ] Create `src/gitctx/core/embedding_cache.py`
- [ ] Create `tests/unit/embeddings/test_embedding_cache.py`
- [ ] Write unit tests BEFORE implementation:
  - [ ] `test_cache_miss_returns_none()` - File doesn't exist
  - [ ] `test_cache_hit_returns_embeddings()` - Load existing file
  - [ ] `test_cache_set_creates_file()` - Save embeddings
  - [ ] `test_cache_directory_created()` - Ensure .gitctx/embeddings/{model}/ exists
  - [ ] `test_cache_key_is_blob_sha()` - Verify filename pattern
  - [ ] `test_cache_roundtrip()` - Set then get returns same data
- [ ] Run tests - all fail âœ“ (RED phase)
- [ ] Implement `EmbeddingCache` class:
  ```python
  from pathlib import Path
  from typing import Optional
  from safetensors.numpy import save_file, load_file
  import numpy as np
  from gitctx.core.models import Embedding

  class EmbeddingCache:
      """Persistent filesystem cache for embeddings by blob SHA."""

      def __init__(self, cache_dir: Path, model: str = "text-embedding-3-large"):
          """Initialize cache for a specific model.

          Args:
              cache_dir: Root cache directory (.gitctx/)
              model: Model name for namespacing (default: text-embedding-3-large)
          """
          self.cache_dir = cache_dir / "embeddings" / model
          self.cache_dir.mkdir(parents=True, exist_ok=True)
          self.model = model

      def get(self, blob_sha: str) -> Optional[list[Embedding]]:
          """Load cached embeddings for a blob.

          Args:
              blob_sha: Git blob SHA

          Returns:
              List of Embedding objects if cached, None if not found
          """
          path = self.cache_dir / f"{blob_sha}.safetensors"
          if not path.exists():
              return None

          # Load safetensor file with metadata
          from safetensors import safe_open

          with safe_open(str(path), framework="numpy") as f:
              metadata = f.metadata() or {}  # Get metadata from file

              # Reconstruct Embedding objects from arrays + metadata
              embeddings = []
              chunk_count = len([k for k in f.keys() if k.startswith("chunk_")])
              for i in range(chunk_count):
                  tensor = f.get_tensor(f"chunk_{i}")
                  vector = tensor.tolist()
                  embeddings.append(Embedding(
                      vector=vector,
                      token_count=int(metadata.get(f"chunk_{i}_tokens", 0)),
                      model=self.model,
                      cost_usd=float(metadata.get(f"chunk_{i}_cost", 0.0)),
                      blob_sha=blob_sha,
                      chunk_index=i,
                  ))
          return embeddings

      def set(self, blob_sha: str, embeddings: list[Embedding]) -> None:
          """Save embeddings to cache.

          Args:
              blob_sha: Git blob SHA
              embeddings: List of Embedding objects to cache
          """
          path = self.cache_dir / f"{blob_sha}.safetensors"

          # Convert Embedding list to numpy arrays for safetensors
          tensors = {}
          metadata = {}
          for i, emb in enumerate(embeddings):
              tensors[f"chunk_{i}"] = np.array(emb.vector, dtype=np.float32)
              metadata[f"chunk_{i}_tokens"] = str(emb.token_count)
              metadata[f"chunk_{i}_cost"] = str(emb.cost_usd)

          metadata["model"] = self.model
          metadata["blob_sha"] = blob_sha
          metadata["chunks"] = str(len(embeddings))

          save_file(tensors, str(path), metadata=metadata)
  ```
- [ ] Run tests - all pass âœ“ (GREEN phase)
- [ ] Type check: `uv run mypy src/gitctx/core/embedding_cache.py`

### BDD Implementation (Scenario 5: Cache Hit)
- [ ] Implement step: "Given a blob with SHA {sha} was previously embedded"
  - [ ] Use EmbeddingCache.set() to pre-populate cache in test fixture
  - [ ] Create mock Embedding objects
- [ ] Implement step: "Then the cached embedding should be returned"
  - [ ] Call embedder.generate() (will be implemented in TASK-3)
  - [ ] Verify returned embeddings match cached values
- [ ] Implement step: "And no API call should be made"
  - [ ] Mock OpenAI client, assert generate() not called
- [ ] Run BDD test: `uv run pytest tests/e2e/features/embedding.feature::test_scenario_5 -v`
- [ ] Expected: Scenario 5 passes (cache logic works, using mock embedder)

### BDD Implementation (Scenario 10)
- [ ] Implement step: "Given GitCtxSettings has no OpenAI API key configured"
  - [ ] Use `config_factory` to create config without API key
- [ ] Implement step: "When I attempt to initialize the OpenAIEmbedder"
  - [ ] Placeholder: `raise NotImplementedError("TASK-0001.2.3.3")`
- [ ] Implement step: "Then a ConfigurationError should be raised"
  - [ ] Assert expected error type
- [ ] Run BDD test: `uv run pytest tests/e2e/features/embedding.feature::test_scenario_10 -v`
- [ ] Expected: Scenario 10 fails (implementation in next task)

### Verification
- [ ] All unit tests pass:
  - [ ] `uv run pytest tests/unit/embeddings/test_embedding.py -v`
  - [ ] `uv run pytest tests/unit/embeddings/test_embedding_cache.py -v`
- [ ] Type checking passes:
  - [ ] `uv run mypy src/gitctx/core/protocols.py`
  - [ ] `uv run mypy src/gitctx/core/embedding_cache.py`
- [ ] BDD Progress: 2/10 scenarios passing
  - [ ] Scenario 5 (cache hit) - passes âœ…
  - [ ] Scenario 10 (config validation) - stubbed (impl in TASK-3)
- [ ] Coverage >90% on new code: `uv run pytest --cov=src/gitctx/core -v`
- [ ] Quality gates: `uv run ruff check src tests && uv run ruff format src tests`

## Pattern Reuse

**Existing Patterns to Follow:**
- Protocol design: `ChunkerProtocol`, `CommitWalkerProtocol` in `src/gitctx/core/protocols.py`
- Dataclass pattern: `src/gitctx/core/models.py` (primitives only, no numpy/Path)
- AAA test structure: `tests/unit/core/test_chunker.py:20-95`
- Parametrization: `pytest.mark.parametrize` for dimension validation

**Fixtures Available:**
- `isolated_env` (tests/unit/conftest.py:13) - Environment isolation
- `config_factory` (tests/unit/conftest.py:604) - Generate test configs

## LangChain v1.0 Alpha Integration

**Why LangChain?**
- Future provider flexibility (OpenAI â†’ Anthropic, Cohere, HuggingFace, etc.)
- Built-in batching, retry, rate limiting
- Standardized embeddings interface
- Active development and community support

**Architecture:**
```
CodeChunk â†’ EmbedderProtocol â†’ OpenAIEmbedder â†’ langchain_openai.OpenAIEmbeddings
           (our interface)     (wrapper)         (provider implementation)
```

**Future Extension:**
```python
# Easy to add new providers
class AnthropicEmbedder:  # Implements EmbedderProtocol
    def __init__(self):
        self._embeddings = langchain_anthropic.AnthropicEmbeddings(...)

class CohereEmbedder:  # Implements EmbedderProtocol
    def __init__(self):
        self._embeddings = langchain_cohere.CohereEmbeddings(...)
```

## Notes

- Use `list[float]` not `numpy.ndarray` (FFI compatible)
- Embedding is immutable (frozen dataclass recommended)
- LangChain v1.0 alpha requires Python â‰¥3.10
- Protocol enables dependency injection for testing
- Cost calculation: `token_count * 0.00000013` ($0.13 per 1M tokens)

## Expected Outcome

**BDD Progress**: 2/10 scenarios passing
- Scenario 5 (cache hit): âœ… Passes with mock embedder
- Scenario 10 (config validation): Stubbed, needs impl in TASK-3

**Files Created**:
- `src/gitctx/core/embedding_cache.py` - Persistent safetensor cache
- `tests/unit/embeddings/test_embedding_cache.py` - Cache unit tests
- Updated `src/gitctx/core/protocols.py` - EmbedderProtocol + Embedding dataclass

**Result**: Foundation ready for OpenAIEmbedder implementation in TASK-0001.2.3.3, with caching infrastructure complete

---

**Created**: 2025-10-07
**Last Updated**: 2025-10-07
