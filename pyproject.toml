[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "gitctx"
version = "0.1.0"
description = "Context optimization engine for coding workflows"
readme = "README.md"
requires-python = ">=3.11"
license = {text = "MIT"}
authors = [
    {name = "Bram Swenson", email="bram@craniumisajar.com"},
]
keywords = ["git", "context", "search", "embeddings", "AI"]
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Programming Language :: Python :: 3.13",
    "Topic :: Software Development :: Version Control :: Git",
]

dependencies = [
    "lancedb>=0.3.0",
    "langchain-core>=1.0.0a0",
    "langchain-openai>=1.0.0a0",
    "langchain-text-splitters>=1.0.0a0",
    "numpy>=1.24.0",
    "pathspec>=0.11.0",
    "pyarrow>=14.0.0",
    "pydantic>=2.11.0",
    "pydantic-settings[yaml]>=2.11.0",
    "pygit2>=1.13.0",
    "pyyaml>=6.0.1",
    "rich>=13.7.0",
    "safetensors>=0.4.0",
    "shellingham>=1.5.0",
    "tiktoken>=0.8.0,<1.0",
    "typer>=0.12.0",
]

[project.optional-dependencies]
dev = [
    "ipython>=9.6.0",
    "pytest>=8.0.0",
    "pytest-bdd>=7.0.0",
    "pytest-cov>=4.1.0",
    "pytest-xdist>=3.5.0",
    "pytest-vcr>=1.0.2",
    "vcrpy>=6.0.1",
    "poethepoet>=0.24.0",
    "mypy>=1.8.0",
    "ruff>=0.1.0",
    "pre-commit>=3.6.0",
    "types-pyyaml>=6.0.12",
    "commitizen>=3.13.0",
    "detect-secrets>=1.4.0",
]

[project.scripts]
gitctx = "gitctx.cli.main:app"

[project.urls]
"Homepage" = "https://gitctx.ai"
"Repository" = "https://github.com/gitctx-ai/gitctx"
"Bug Tracker" = "https://github.com/gitctx-ai/gitctx/issues"
"Documentation" = "https://github.com/gitctx-ai/gitctx/docs"

[tool.hatch.build.targets.wheel]
packages = ["src/gitctx"]

[tool.ruff]
line-length = 100
target-version = "py311"
src = ["src", "tests"]

[tool.ruff.lint]
select = [
    "E",     # pycodestyle errors
    "W",     # pycodestyle warnings
    "F",     # pyflakes
    "I",     # isort
    "B",     # flake8-bugbear
    "C4",    # flake8-comprehensions
    "UP",    # pyupgrade
    "ARG",   # flake8-unused-arguments
    "SIM",   # flake8-simplify
    "PLC",   # Pylint conventions
    "PLW",   # Pylint warnings
    "PLR",   # Pylint refactor
    "RUF",   # Ruff-specific rules
    "PT",    # flake8-pytest-style
    "PIE",   # flake8-pie
    "PERF",  # Perflint (performance)
]
ignore = [
    # No ignores - enforcing all selected rules including 100 char line limit
]

[tool.ruff.format]
quote-style = "double"
indent-style = "space"

[tool.ruff.lint.per-file-ignores]
"tests/**/*.py" = [
    "ARG001",   # Unused function argument (mocks often don't use args)
    "ARG002",   # Unused method argument (fixtures are often unused in test body)
    "PLR2004",  # Magic value comparison (test data often has literals)
    "PLR0912",  # Too many branches (test helpers/fixtures need complexity)
    "PLR0913",  # Too many arguments (test helpers/fixtures need many params)
    "PLR0915",  # Too many statements (test setup/teardown can be long)
    "RUF001",   # Ambiguous unicode (intentional for unicode tests)
]
"src/gitctx/indexing/pipeline.py" = [
    "PLR0915",  # index_repository is complex pipeline orchestration
]

[tool.mypy]
python_version = "3.11"
strict = true
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_any_unimported = true
no_implicit_optional = true
warn_redundant_casts = true
warn_unused_ignores = true
warn_no_return = true
check_untyped_defs = true

[[tool.mypy.overrides]]
module = "tests.*"
disallow_untyped_defs = false
check_untyped_defs = true

[[tool.mypy.overrides]]
module = "pygit2.*"
ignore_missing_imports = true

[[tool.mypy.overrides]]
module = "langchain_text_splitters.*"
ignore_missing_imports = true
follow_imports = "skip"

[[tool.mypy.overrides]]
module = "tiktoken.*"
ignore_missing_imports = true
follow_imports = "skip"

[[tool.mypy.overrides]]
module = "langchain_openai.*"
ignore_missing_imports = true
follow_imports = "skip"

[[tool.mypy.overrides]]
module = "langchain_core.*"
ignore_missing_imports = true
follow_imports = "skip"

[[tool.mypy.overrides]]
module = "gitctx.git.walker"
warn_unused_ignores = false
disallow_any_unimported = false
# Reason: Uses pygit2 library which has incomplete type stubs (Any leakage in Tree/Commit types)
# Ticket: TASK-TBD (Create protocol wrappers for pygit2 types)
# Target: EPIC-0001.4 completion (Indexing improvements) or 2025-Q3

[[tool.mypy.overrides]]
module = "gitctx.storage.embedding_cache"
warn_unused_ignores = false
# Reason: Legacy module with unused type ignores from previous implementation
# Ticket: TASK-TBD (Audit and remove unnecessary type ignores)
# Target: 2025-Q2 (Low priority - module works correctly)

[[tool.mypy.overrides]]
module = "gitctx.models.providers.openai"
warn_unused_ignores = false
# Reason: OpenAI SDK has evolving type signatures, some type ignores may be stale
# Ticket: TASK-TBD (Review after OpenAI SDK 2.0 stabilizes)
# Target: 2025-Q2 (When SDK types are stable)

[[tool.mypy.overrides]]
module = "gitctx.search.embeddings"
warn_unused_ignores = false
# Reason: Numpy array type annotations cause spurious mypy warnings about ignores
# Ticket: TASK-TBD (Investigate numpy type stub compatibility)
# Target: 2025-Q2 (After numpy 2.0 type stubs mature)

[[tool.mypy.overrides]]
module = "openai.*"
ignore_missing_imports = true
follow_imports = "skip"

[[tool.mypy.overrides]]
module = "numpy.*"
ignore_missing_imports = true
follow_imports = "skip"

[[tool.mypy.overrides]]
module = "safetensors.*"
ignore_missing_imports = true
follow_imports = "skip"

[[tool.mypy.overrides]]
module = "lancedb.*"
ignore_missing_imports = true
follow_imports = "skip"

[[tool.mypy.overrides]]
module = "pyarrow.*"
ignore_missing_imports = true
follow_imports = "skip"

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py", "*_test.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
addopts = [
    "-ra",
    "--strict-markers",
    "--strict-config",
    "--cov=src/gitctx",
    "--cov-branch",
    "--cov-report=term-missing:skip-covered",
    "--cov-report=html",
    "--cov-report=xml",
    "--color=yes",
    "-m",
    "not performance",
]
markers = [
    "slow: marks tests as slow (deselect with '-m \"not slow\"')",
    "integration: marks tests as integration tests",
    "unit: marks tests as unit tests",
    "anyio: marks tests using anyio for async operations",
    "vcr: marks tests using VCR cassettes for API recording/replay",
    "performance: marks tests as performance tests (p95 latency, throughput)",
    "formatting: marks tests for result formatting (terse, verbose, MCP)",
]

[tool.coverage.run]
branch = true
source = ["src/gitctx"]
parallel = true
concurrency = ["multiprocessing"]
omit = [
    "*/tests/*",
    "*/__main__.py",
]

[tool.coverage.report]
exclude_lines = [
    "pragma: no cover",
    "def __repr__",
    "if self.debug:",
    "if settings.DEBUG",
    "raise AssertionError",
    "raise NotImplementedError",
    "if 0:",
    "if __name__ == '__main__':",
    "if TYPE_CHECKING:",
    "class .*\\bProtocol\\):",
    "@(abc\\.)?abstractmethod",
]
precision = 2
show_missing = true
skip_covered = false
fail_under = 85

[tool.coverage.html]
directory = "htmlcov"

# Custom scripts
[tool.poe.tasks]

[tool.poe.tasks.quality]
sequence = [
    { cmd = "ruff check src tests" },
    { cmd = "ruff format --check src tests" },
    { cmd = "mypy src" },
    { cmd = "pytest" },
]
ignore_fail = false

[tool.poe.tasks.fix]
sequence = [
    { cmd = "ruff check --fix src tests" },
    { cmd = "ruff format src tests" },
]

[tool.poe.tasks.test]
cmd = "pytest"

[tool.poe.tasks.test-unit]
cmd = "pytest tests/unit -v"

[tool.poe.tasks.test-e2e]
cmd = "pytest tests/e2e -v"

[tool.poe.tasks.test-cov]
cmd = "pytest --cov=src/gitctx --cov-report=html"

[tool.poe.tasks.install-hooks]
sequence = [
    { cmd = "pre-commit install --install-hooks" },
    { cmd = "pre-commit install --hook-type commit-msg" },
    { cmd = "pre-commit run --all-files" },
]
help = "Install and test pre-commit hooks"

# === GitHub PR Review Comment Management ===

[tool.poe.tasks.pr-reply]
shell = """
gh api graphql -f query='
mutation {
  addPullRequestReviewThreadReply(input: {
    pullRequestReviewThreadId: "'$THREAD_ID'"
    body: "'$BODY'"
  }) {
    comment {
      id
    }
  }
}'
"""
help = "Reply to a PR review comment thread. Requires: THREAD_ID, BODY env vars"

[tool.poe.tasks.pr-resolve]
shell = """
gh api graphql -f query='
mutation {
  resolveReviewThread(input: {
    threadId: "'$THREAD_ID'"
  }) {
    thread {
      id
      isResolved
    }
  }
}'
"""
help = "Resolve a PR review comment thread. Requires: THREAD_ID env var"

[tool.poe.tasks.pr-find-thread]
shell = """
gh api graphql -f query='
query {
  repository(owner: "'${OWNER:-gitctx-ai}'", name: "'${REPO:-gitctx}'") {
    pullRequest(number: '${PR_NUMBER}') {
      reviewThreads(first: 50) {
        nodes {
          id
          isResolved
          comments(first: 1) {
            nodes {
              databaseId
              body
            }
          }
        }
      }
    }
  }
}' --jq '.data.repository.pullRequest.reviewThreads.nodes[] | select(.comments.nodes[0].databaseId == '${COMMENT_ID}') | {threadId: .id, isResolved, commentBody: .comments.nodes[0].body}'
"""
help = "Find thread ID by comment ID. Requires: PR_NUMBER, COMMENT_ID env vars. Optional: OWNER, REPO"

[tool.poe.tasks.pr-address-comment]
shell = """
# Complete workflow: find thread ID, reply, and resolve
# Automatically gets correct GitHub username from 'gh api user'

# Get authenticated user's GitHub username
GH_USERNAME=$(gh api user --jq '.login')

echo "Step 1: Finding thread ID for comment ${COMMENT_ID}..."
THREAD_ID=$(gh api graphql -f query='
query {
  repository(owner: "'${OWNER:-gitctx-ai}'", name: "'${REPO:-gitctx}'") {
    pullRequest(number: '${PR_NUMBER}') {
      reviewThreads(first: 50) {
        nodes {
          id
          comments(first: 1) {
            nodes {
              databaseId
            }
          }
        }
      }
    }
  }
}' --jq '.data.repository.pullRequest.reviewThreads.nodes[] | select(.comments.nodes[0].databaseId == '${COMMENT_ID}') | .id' | tr -d '\\n')

if [ -z "$THREAD_ID" ]; then
  echo "Error: Could not find thread for comment ${COMMENT_ID}"
  exit 1
fi

echo "Found thread: $THREAD_ID"

# Step 2: Reply to the thread (automatically add "On behalf of @username" footer)
echo "Step 2: Adding reply (on behalf of @$GH_USERNAME)..."

# Construct the full reply body with attribution
FULL_REPLY="$REPLY_BODY

---
*On behalf of @$GH_USERNAME*"

# Use jq to properly JSON-encode the body (handles newlines, quotes, etc.)
BODY_JSON=$(echo "$FULL_REPLY" | jq -Rs .)

# Use the properly encoded body in GraphQL mutation
RESULT=$(gh api graphql -f query='
mutation($threadId: ID!, $body: String!) {
  addPullRequestReviewThreadReply(input: {
    pullRequestReviewThreadId: $threadId
    body: $body
  }) {
    comment {
      id
      url
    }
  }
}' -f threadId="$THREAD_ID" -f body="$FULL_REPLY" 2>&1)

if echo "$RESULT" | grep -q '"id"'; then
  echo "Reply added successfully"
else
  echo "ERROR adding reply:"
  echo "$RESULT"
  exit 1
fi

# Step 3: Resolve the thread
echo "Step 3: Resolving thread..."
RESOLVE_RESULT=$(gh api graphql -f query='
mutation {
  resolveReviewThread(input: {
    threadId: "'$THREAD_ID'"
  }) {
    thread {
      id
      isResolved
    }
  }
}' 2>&1)

if echo "$RESOLVE_RESULT" | grep -q '"isResolved":true'; then
  echo "✅ Comment ${COMMENT_ID} addressed: replied and resolved"
else
  echo "ERROR resolving thread:"
  echo "$RESOLVE_RESULT"
  exit 1
fi
"""
help = "Complete workflow to address a PR comment (auto-adds username). Requires: PR_NUMBER, COMMENT_ID, REPLY_BODY env vars. Optional: OWNER, REPO"
